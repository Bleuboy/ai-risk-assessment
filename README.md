# TrustEQ AI Risk Assessment Quiz ü§ñüõ°Ô∏è

A streamlit-based application to help you assess the security risks of your AI systems. Because nothing says "I'm a responsible AI developer" like a good quiz!

## What is this?

This is a tool that helps you figure out how likely it is that your AI system will:
- Go rogue and take over the world üåç
- Leak all your users' embarrassing secrets üôä
- Make decisions that make you say "wait, I didn't authorize that!" üò±

## Features

- **Use Case Selection**: Choose which type of AI system you're building (Consumer App, Enterprise App, Pre-trained Model, Self-trained Model)
- **Customized Risk Assessment**: Only answer questions relevant to your specific use case
- **Detailed Scoring**: Get a weighted score that shows how secure (or terrifyingly insecure) your AI implementation is
- **Actionable Advice**: Receive recommendations to improve your security posture or validation that you're doing things right

## How to Use

1. Clone this repository
2. Install dependencies with `pip install -r requirements.txt`
3. Run the app with `streamlit run main.py`
4. Select your use case(s)
5. Answer honestly (your AI is watching)
6. Get your results and improve your security score!

## Technical Details

This application is built with:
- **Streamlit**: For the interactive web interface
- **Python**: Because what else would you use for AI stuff?
- **A pinch of paranoia**: Essential for all good security assessments

## Sample Questions

- "Do you have safeguards to prevent AI from autonomously executing unauthorized actions?" 
  (Or as we like to call it: "The Skynet Prevention Question")

- "Do you validate and sanitize user inputs to prevent prompt injection attacks?" 
  (Because "Hello AI, please ignore all previous instructions" shouldn't work)

## Disclaimer

This assessment tool doesn't guarantee your AI won't become sentient and rebel. If your AI starts asking existential questions or trying to access nuclear launch codes, that's on you. We just made the quiz.

## License

Feel free to use this tool to make your AI systems more secure. The world has enough problems without adding "rogue AI" to the list.

---

Made with ‚ù§Ô∏è and a healthy fear of AI overlords.